{"cells":[{"cell_type":"markdown","source":"# Scraping overview\n\n### 1. Growing/gathering the related artist network using the Spotify API\n\n### 2. Fetching a list of available songs for each artist from Genius API\n\n### 3. Scraping the lyrics for each song\n\n### 4. Additionally fetching the release date for each song from Genius API\n\n\n","metadata":{"tags":[],"cell_id":"00000-399fc382-1486-4c2e-927f-ed918d0c284f","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-33afd0d9-5ee5-4daf-a947-1627d8ead2e6","output_cleared":false,"source_hash":"8b8d7f8e","execution_millis":228,"execution_start":1607178415463,"deepnote_cell_type":"code"},"source":"import requests\nimport json\nimport pandas as pd\nimport glob\nimport numpy as np\nimport time\nimport concurrent.futures\nimport matplotlib.pyplot as plt\nimport lyricsgenius as lg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Variables","metadata":{"tags":[],"cell_id":"00001-07f10fe0-4543-4c21-a44f-b1964bcec14c","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-5788416a-c521-4623-8703-eb2918689269","output_cleared":false,"source_hash":"7493bdb9","execution_millis":2,"execution_start":1607178415701,"deepnote_cell_type":"code"},"source":"# Spotify API\nAPI_artists = 'https://api.spotify.com/v1/artists/'\nAPI_search = 'https://api.spotify.com/v1/search/'\n# Genius API\nAPI_base = 'https://api.genius.com'\nAPI_search = API_base + '/search?q='\n\n\n# Local directory path names\nurl_rel_done = '../Data/Spotify_rel_done.txt'\nurl_rel_links = '../Data/Spotify_related_link_list.csv'\n# Data for artist network\nurl_artist = '../Data/Related artist network data/artists.csv'\nurl_edges = '../Data/Related artist network data/edges.csv'\nurl_genres = '../Data/Related artist network data/genres.txt'\n\nurl_genius_songs = '../Data/Lyrics data/lyrics.csv'\nurl_genius_relase_date = '../Data/Lyrics data/song_release_date.csv'\n\nurl_spotify_token = '../Data/authorization_code_spotify.txt'\nurl_genius_token = '../Data/authorization_code_genius.txt'\n\n# For authentication\nspotify_token = open(url_spotify_token).read().replace(\"\\n\", \" \")\nspotify_headers = {\"Authorization\": \"Bearer \" + spotify_token}\n\n# Token\ngenius_token = open(url_genius_token).read().replace(\"\\n\", \" \")\ngenius_headers = {\"Authorization\": \"Bearer \" + genius_token}\n\n# Seed for related artists crawler\nKanye_ID = '5K4W6rqBFWDnAN6FQUkS6x'\n\n# other data\ndefault_columns = ['name','id','followers','popularity','genres']\nfinal_columns = ['name','id','followers','popularity']\n\n# Empty container for final dataframe\nempty_df = pd.DataFrame(columns = ['name','id','followers','popularity','genres'])\n\n\n# Search url\nAPI_base = 'https://api.genius.com'\nAPI_search = API_base + '/search?q=' \n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions\n\n## General functions\n- **execute query:** Takes in a query and sends a request using the header defined in the variables seciton\n- **concurrent_requests:** asynchronously calls the given function over the iterable given and returns the results a list of futures\n\n\n## Spotify functions\n- **get_raw_related_artist_responses:** Takes in a spotify artist ID, returns a json reponse with related artists\n- **concurrent_related_artist_requests:** asynchronously calls <code>get_raw_related_artists</code> and returns a list of futures\n- **process_raw_related_artist_responses:** Takes in the response from <code>get_raw_related_artists</code> and outputs three objects:\n    - <code>artist_df</code>: a pandas dataframe with the variables of interest about each artist\n    - <code>genre_dict</code>: a dictionary with a single key, which is the artist ID and the value is the list of the artists genres\n    - <code>new_edges</code>: a pandas dataframe with a <code>from</code> column for the ID of the artist and a <code>to</code> column with the related artist from the reponse \n\n\n\n","metadata":{"tags":[],"cell_id":"00004-91a194e0-d1b7-48bd-9b4e-ef19c7097d71","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-c58c0310-688c-49f7-9da0-8f9b218bad69","output_cleared":false,"source_hash":"fe1a22c1","execution_millis":4,"execution_start":1607178415709,"deepnote_cell_type":"code"},"source":"# General functions\ndef execute_query(query,return_string = False):\n    if 'spotify' in query.lower():\n        headers = spotify_headers\n    else:\n        headers = genius_headers\n\n    response = requests.get(url = query,headers=headers).json()\n    if return_string:\n        return json.dumps(response, indent=2)\n    return response\n\ndef concurrent_requests(iterable, function):\n    future_list = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n        for i in iterable:\n            future = executor.submit(function, i)\n            future_list.append(future)\n\n    return future_list","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-5a6b38d6-0478-465f-96de-1745381fa7a5","output_cleared":false,"source_hash":"ac8126c3","execution_millis":3,"execution_start":1607178415718,"deepnote_cell_type":"code"},"source":"# Spotify functions\ndef process_raw_song_responses(response,artist_name):\n    # load response\n    response_content = response['response']\n\n    # Extract data and insert into dataframe\n    hits_df = pd.DataFrame(response_content['hits'])\n    if len(hits_df) == 0:\n        return hits_df\n    hits_df = pd.DataFrame(list(hits_df.result.values))\n    hits_df.loc[:,'primary_artist'] = hits_df.loc[:,'primary_artist'].apply(lambda x : x['name'])\n    hits_df = hits_df[hits_df.primary_artist == artist_name]\n    return hits_df\n\ndef get_raw_related_artist_responses(ID):\n    query = API_artists + f'{ID}/related-artists' \n    response = execute_query(query)\n    return response\n\n\ndef concurrent_related_artist_requests(id_list):\n    return concurrent_requests(id_list,get_raw_related_artist_responses)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spotify: Getters and setters\n\n- Artist dataframe\n- Edge dataframe\n- Genre dictionary\n","metadata":{"tags":[],"cell_id":"00007-937f7937-41a3-4ad1-9c80-c53c914eb4cc","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00011-f50cced0-3ae9-44b3-950c-addda8d21962","output_cleared":false,"source_hash":"aa7c0d43","execution_millis":3,"execution_start":1607178415725,"deepnote_cell_type":"code"},"source":"# Spotify getters & setters\n# For artist dataframe\ndef save_current_artist_dataframe(df):\n    df.to_csv(url_artist)\n\ndef load_current_artist_dataframe():\n    return pd.read_csv(url_artist,index_col=0)\n\n# For edges dataframe\ndef save_current_edge_dataframe(df):\n    df.index = np.arange(len(df))\n    df.to_csv(url_edges)\n\ndef load_current_edge_dataframe():\n    return pd.read_csv(url_edges,index_col=0)\n\n# For the genre dictionary\ndef save_current_genre_dict(dictionary):\n    file_object = open(url_genres,'w')\n    file_object.write(json.dumps(dictionary))\n    file_object.close()\n\ndef load_current_genre_dict():\n    string = open(url_genres).read()\n    json_object = json.loads(string)\n    return json_object \n\n# aggregate functions for all three\ndef save_all(artists,genre_dict,edges):\n    save_current_genre_dict(genre_dict)\n    save_current_edge_dataframe(edges)\n    save_current_artist_dataframe(artists)\n\ndef load_all():\n    genre_dict = load_current_genre_dict()\n    edges = load_current_edge_dataframe()\n    artists = load_current_artist_dataframe()\n    return artists,genre_dict,edges","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spotify related artists crawler\n\n## Settings\n- <code>batch_size</code>: Number of artists to query asyncronously in each iteration\n- <code>Stopping size</code>: number of artist required before stopping\n\n## Crawler description\n**For each iteration:**\n\n0. (Unless being run for the first time) Reload previously saved artists\n1. Create a list of unseached artists\n2. Select a batch from the unsearched artists, selecting first the ones with the highest popularity score\n3. Call asyncronous function to get a batch of unprocessed responses\n4. For each response:\n    1. Process response using <code>process_raw_related_artist_responses</code>\n    2. Handle if the response was empty. Only mark as searched if artist had no related artist, not if the API returned an error\n    3. Add the new artist to the completed data objects\n5. Save data objects after every batch","metadata":{"tags":[],"cell_id":"00014-5a654009-7def-4c35-ab17-b97dfad16eac","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-b35ead77-4f5e-4227-b8d9-35b4991c73c8","output_cleared":false,"source_hash":"40f686b1","execution_millis":954,"execution_start":1607178415735,"deepnote_cell_type":"code"},"source":"artists,genre_dict,edges = load_all()\n\nbatch_size = 100\nstopping_size = 100_000\n\nwhile len(artists) < stopping_size:\n    \n    artists = artists.sort_values(['popularity','followers'],ascending=False)\n    unsearched_ids = artists.loc[artists.searched == False].index.values\n    current_batch = unsearched_ids[:batch_size].copy()\n    \n    # Make the requests concurrently\n    future_list = concurrent_related_artist_requests(current_batch)\n\n    # then process the requests\n    results = [x.result() for x in future_list]\n    for ID,response in zip(current_batch,results):\n\n        tmp_artist, tmp_genre_dict, tmp_new_edges = process_raw_related_artist_responses(response,ID)\n        if len(tmp_new_edges) == 0:\n            print(tmp_genre_dict)\n            if tmp_genre_dict['error'] == 'problem':\n                break\n            elif tmp_genre_dict['error'] == 'no relation':\n                # end of the road, this artist has no related artists\n                artists.at[ID,'searched'] = True\n                continue\n            else:\n                print('unexplained error')\n                break\n        # append new ids to the artis dataframe\n        for i in tmp_artist.index.values:\n            if i not in artists.index:\n                artists.loc[i,:] = None\n                artists.loc[i,:] = tmp_artist.loc[i,:]\n\n        # Add new genres to genre_dict\n        genre_dict.update(tmp_genre_dict)\n        \n        len(tmp_new_edges)\n        # add new edges to the edge list\n        edges = pd.concat([edges,tmp_new_edges],ignore_index=True)\n\n        artists.at[ID,'searched'] = True\n\n    save_all(artists,genre_dict,edges)\n    print(len(unsearched_ids),len(artists),len(edges))\n    ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Fetching a list of available songs for each artist from Genius API","metadata":{"tags":[],"cell_id":"00016-38701616-3151-462d-8dae-abfec6814c3e","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Helper functions\n\n- <code>get_raw_artist_songs</code> fetch songs for a single artist\n- <code>concurrent_get_songs_requests</code> asynchronously call a batch of artist song requests\n- <code>process_raw_song_responses</code> process the requests","metadata":{"tags":[],"cell_id":"00012-1c4aedfd-afa7-4465-9dbb-c26dc81b12c5","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-1d42ceb0-2d1e-4122-9245-3d9339869c4e","output_cleared":false,"source_hash":"89536a4b","execution_millis":3,"execution_start":1607178416694,"deepnote_cell_type":"code"},"source":"def get_raw_artist_songs(artist_name):\n    q = API_search + artist_name\n    response = execute_query(q)\n    return response\n   \ndef concurrent_get_songs_requests(artist_names):\n    return concurrent_requests(artist_names,get_raw_artist_songs)\n\ndef process_raw_song_responses(response,artist_name):\n    # load response\n    response_content = response['response']\n\n    # Extract data and insert into dataframe\n    hits_df = pd.DataFrame(response_content['hits'])\n    if len(hits_df) == 0:\n        return hits_df\n    hits_df = pd.DataFrame(list(hits_df.result.values))\n    hits_df.loc[:,'primary_artist'] = hits_df.loc[:,'primary_artist'].apply(lambda x : x['name'])\n    hits_df = hits_df[hits_df.primary_artist == artist_name]\n    return hits_df\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Genius: Getters and setters\n- Song list dataframe\n","metadata":{"tags":[],"cell_id":"00015-513ad667-f4e6-4485-981e-fe93f37dbb4e","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-814bf3da-3e5b-4062-9e94-53b10f936343","output_cleared":false,"source_hash":"d4c55aef","execution_millis":1,"execution_start":1607178416699,"deepnote_cell_type":"code"},"source":"# Genius\ndef load_songs():\n    df = pd.read_csv(url_genius_songs,index_col=0)\n    df.index = np.arange(len(df))\n    return df\n\ndef save_songs(dataframe):\n    dataframe.to_csv(url_genius_songs)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fetching and saving songs from Genius\n\n1. (Unless being run for the first time) Reload previously saved list of songs\n2. Create the list of artist which we want to fetch songs for (~4000 artists)\n    - *See explainer notebook for more details on why this was done*\n3. Create a running list of artists that have already been queried\n4. Iteratively do the following\n    - Select a batch of un-searched artists\n    - Call <code>concurrent_get_songs_requests</code> for these artists to asynchronously get the song data for each artist\n    - Process the batch of responses, making sure to include at least the following variables of interest:\n        - <code>api_path</code>: For later querying of release date from API\n        - <code>path</code>: For later scraping of lyrics from website\n        - <code>title</code>: for identification of unique songs\n        - <code>primary_artist</code>: for unique identification of songs, aggregation by artist and connection to network\n","metadata":{"tags":[],"cell_id":"00016-155798d6-f703-4368-8537-467c45873339","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-8c1cc728-d0fa-46d0-9591-e21c2dd0a9b1","output_cleared":false,"source_hash":"fdae28f5","execution_millis":759,"execution_start":1607178416707,"deepnote_cell_type":"code"},"source":"songs = load_songs()\n\ntop_popularity = artists.sort_values('popularity',ascending=False).iloc[:3000]\ntop_followers = artists.sort_values('followers',ascending=False).iloc[:3000]\ntop_both = artists.loc[top_popularity.index.union(top_followers.index)]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00018-7f991f19-c680-4e30-a740-bb5b6c310368","output_cleared":false,"source_hash":"c2451c01","execution_millis":6668,"execution_start":1607178417472,"deepnote_cell_type":"code"},"source":"already_searched = list(songs.primary_artist.unique())\nbatch_size = 205\nnew_added = 1\nwhile new_added > 0:\n    start,end = 0,batch_size\n    # print(f'batch: {i} of {total_batches}')\n    batch = top_both.loc[~top_both.name.isin(already_searched)].name.values[start:end]\n    print('starting concurrent')\n    song_response_future_list = concurrent_get_songs_requests(batch)\n    print('extracting results')\n    song_response_results = [x.result() for x in song_response_future_list]\n    print('processing')\n    processed_responses = [process_raw_song_responses(response,artist_name) for response,artist_name in zip(song_response_results,batch)]\n    print('saving')\n    song_batch_df = pd.concat(processed_responses)\n    songs = pd.concat([songs,song_batch_df])\n    songs = songs.drop_duplicates(['primary_artist','title'])\n    already_searched = already_searched + list(batch)\n    new_added = len(song_batch_df)\n    print(new_added, 'new songs, now', len(songs),' in total')\n    save_songs(songs)\n","execution_count":null,"outputs":[{"name":"stdout","text":"starting concurrent\nextracting results\nprocessing\nsaving\n0 new songs, now 27436  in total\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Scraping the lyrics for each song\n1. Create an instance of a lyricsgenius object specifically designed to help with scraping from the genius website\n    - **Note:** Due to [legal reasons](https://genius.com/discussions/277279-Get-the-lyrics-of-a-song) Genius does not offer direct API access to the lyrics for songs, but instead we can use this package, which has been made to directly scrape the lyrics from the site itself. \n2. Create a list of songs which have not been scraped\n3. In batches of 1000 at a time and until no songs are yet unsearched\n    - Scrape the lyrics using lyricsgenius lyrics scraper from the website\n    - Update and save the dataframe after each iteration  ","metadata":{"tags":[],"cell_id":"00020-10aa47a6-b8b4-46d6-9960-2f565888240c","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Genius lyrics: Helper functions\n- <code>concurrent_get_songs_requests</code> asynchronously call the lyricsgenius objects built in function <code>lyrics</code> with the url to each song","metadata":{"tags":[],"cell_id":"00021-2c9b0967-b752-4b12-b774-1a6e6bf80d4e","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00022-34fb4f7c-6868-4d85-9733-dffa08a2c0ce","output_cleared":false,"source_hash":"a4d9016","execution_millis":1,"execution_start":1607178424145,"deepnote_cell_type":"code"},"source":"def concurrent_get_songs_requests(urls):\n    return concurrent_requests(urls,lambda x: genius.lyrics(x))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00020-d26bd370-284f-475a-9179-39918009c414","output_cleared":false,"source_hash":"4be88e6e","execution_millis":15977,"execution_start":1607178424155,"deepnote_cell_type":"code"},"source":"genius = lg.Genius(genius_token, skip_non_songs=True, excluded_terms=[\"(Remix)\", \"(Live)\"], remove_section_headers=True, verbose=False)\nunsearched_urls = songs.loc[songs.lyrics.isna(),'url']\nbatch_size = 1000\nwhile(len(unsearched_urls) > 0):\n    print(f'{len(unsearched_urls)} unsearched lyrics...')\n    batch = unsearched_urls[:batch_size]\n    lyrics_futures = concurrent_get_songs_requests(batch.values)\n    lyrics_batch = pd.Series([x.result() for x in lyrics_futures])\n    lyrics_batch.loc[lyrics_batch.isna()] = ''\n    songs.loc[batch.index,'lyrics'] = lyrics_batch.values\n    save_songs(songs)\n    unsearched_urls = songs.loc[songs.lyrics.isna(),'url']","execution_count":null,"outputs":[{"name":"stdout","text":"387 unsearched lyrics...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Additionally fetching the meta-data for each song from Genius API\n- We're mainly interested in the release date here, but there is more data available here which could be used for more analysis","metadata":{"tags":[],"cell_id":"00020-14ebf874-2ed8-488d-b050-7a6f91b9e50b","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Genius song meta-data fetch: helper functions","metadata":{"tags":[],"cell_id":"00024-12aea664-537f-495f-928c-69ea57e67b0d","output_cleared":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00024-f3ae2b96-cf8b-4d25-9d98-3f38bc0ec449","output_cleared":false,"source_hash":"ee5e0466","execution_millis":0,"execution_start":1607178440133,"deepnote_cell_type":"code"},"source":"def concurrent_get_songs_metadata_requests(urls):\n    return concurrent_requests(urls,lambda x: execute_query(API_base + x))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00021-f034bdaf-3e13-4502-abb8-220ffeaa1410","output_cleared":false,"source_hash":"b8873393","execution_millis":0,"execution_start":1607178440134,"deepnote_cell_type":"code"},"source":"try:\n    relase_dates = pd.read_csv(url_genius_relase_date,index_col = 0)\nexcept:\n    print('No such file exists... creating from scratch.')\n    futures = concurrent_get_songs_metadata_requests(songs.api_path.values)\n    results = [x.result()['response']['song'] for x in futures if x.result()['meta']['status'] != 404]\n    songs_metadata = pd.DataFrame(results)\n    relase_dates = tmp_songs_metadata.loc[:,['api_path','title','release_date','primary_artist']]\n    relase_dates.primary_artist = relase_dates.primary_artist.apply(lambda x : x['name'])\n    relase_dates.to_csv(url_genius_relase_date)","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"f7bb2399-2f21-4630-aba3-c3574ed3d426","deepnote_execution_queue":[]}}